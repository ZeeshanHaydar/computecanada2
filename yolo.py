# -*- coding: utf-8 -*-
"""yolo.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1x6woZ6_6L4B42BVMJ5Aan0PWm2wiksu2
"""

import pandas as pd
import os
import glob
from PIL import Image, ImageDraw
import numpy as np
import matplotlib.pyplot as plt
import random
from sklearn.model_selection import train_test_split
import shutil
import torch
from IPython.display import Image  # for displaying images
import os 
import random
import shutil
import PIL

path = '/content/drive/MyDrive/FINAL/train_f.csv'

df = pd.read_csv(path)

print(df['name'].unique())
print(df.name.unique())

# Convert to List
print(df.name.unique().tolist())

cd /content/drive/MyDrive/FINAL

!mkdir labels images

!mkdir  labels/train labels/val images/train images/val

# Creating the list of images from the excel sheet
imgs = df['image_path'].unique().tolist()
# Loop through each of the image
for img in imgs:
    boundingDetails = []
    # First get the bounding box information for a particular image from the excel sheet
    boundingInfo = df.loc[df.image_path == img,:]
    # Loop through each row of the details
    for idx, row in boundingInfo.iterrows():
        # Get the class Id for the row
        class_id =row["class"]
        # Convert the bounding box info into the format for YOLOV5
        # Get the width
        bb_width = row['xmax'] - row['xmin']
        # Get the height
        bb_height = row['ymax'] - row['ymin']
        # Get the centre coordinates
        bb_xcentre = (row['xmin'] + row['xmax'])/2
        bb_ycentre = (row['ymin'] + row['ymax'])/2
        # Normalise the coordinates by diving by width and height

        bb_xcentre /= row['width'] 
        bb_ycentre /= row['height'] 
        bb_width    /= row['width'] 
        bb_height   /= row['height']  
        #Append details in the list 
        boundingDetails.append("{} {:.3f} {:.3f} {:.3f} {:.3f}".format(class_id, bb_xcentre, bb_ycentre, bb_width, bb_height))
    # Create the file name to save this info     
    file_name = os.path.join("labels", img.split(".")[0] + ".txt")
    # Save the annotation to disk
    print("\n".join(boundingDetails), file= open(file_name, "w"))

annotations = glob.glob('labels' + '/*.txt')
annotations

# Get the list of images from its folder
imagePath = '/content/drive/MyDrive/FINAL/Training_Images'
images = glob.glob(imagePath + '/*.jpg')
images

# Sort the annotations and images and the prepare the train ,test and validation sets
images.sort()
annotations.sort()
 
# Split the dataset into train-valid-test splits 
train_images, val_images, train_annotations, val_annotations = train_test_split(images, annotations, test_size = 0.2, random_state = 123)
#val_images, test_images, val_annotations, test_annotations = train_test_split(val_images, val_annotations, test_size = 0.5, random_state = 123)

#Utility function to copy images to destination folder
def move_files_to_folder(list_of_files, destination_folder):
    for f in list_of_files:
        try:
            shutil.copy(f, destination_folder)
        except:
            print(f)
            assert False

# Copy the splits into the respective folders
move_files_to_folder(train_images, 'images/train')
move_files_to_folder(val_images, 'images/val')
#move_files_to_folder(test_images, 'potholeData/images/test/')
move_files_to_folder(train_annotations, 'labels/train')
move_files_to_folder(val_annotations, 'labels/val')
#move_files_to_folder(test_annotations, 'potholeData/labels/test/')

cd /content/drive/MyDrive/changed

!git clone https://github.com/WongKinYiu/yolov7.git

cd /content/drive/MyDrive/changed/yolov7

!pip install -r requirements.txt

!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt

!python train.py --workers 8 --device 0 --batch-size 8 --data data/coco.yaml --img 640 640 --cfg cfg/training/yolov7.yaml --weights 'yolov7_training.pt' --name yolov7_custom1 --hyp data/hyp.scratch.custom.yaml --epoch 25

